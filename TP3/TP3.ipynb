{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE-411, HomeWork 3 : Neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backpropagation with logistic loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = 5\n",
    "K = 6\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def predict(X, W):\n",
    "    # X: B x D\n",
    "    # W: {w1: D x K, w2: K x 1}\n",
    "    # z1: B x K\n",
    "    # z2: B x 1\n",
    "    # yhat: B x 1\n",
    "    z1 = np.dot(X, W['w1'])\n",
    "    x1 = sigmoid(z1)\n",
    "    z2 = np.dot(x1, W['w2'])\n",
    "    yhat = sigmoid(z2)\n",
    "    return z1, z2, yhat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)Logistic Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_loss(y, yhat):\n",
    "    # y: B x 1\n",
    "    # yhat: B x 1\n",
    "    # loss: B x 1\n",
    "    B = y.shape[0]\n",
    "    loss_sum = np.sum(-y * np.log(yhat) - (1 - y) * np.log(1 - yhat)) / B\n",
    "    return loss_sum\n",
    "\n",
    "\n",
    "# testing with yhat =  y -> 0, not possible to compute log(0)\n",
    "y = np.ones(10)    * 0.000000000000000\n",
    "yhat = np.ones(10) * 0.000000000000000001\n",
    "print(logistic_loss(y, yhat))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\mathbf y \\simeq \\mathbf{\\^{y}} \\simeq 0$, we get an average logistic loss of nearly 0 for the whole batch. This is expected, as the expected value and the ground truth are equal. However, $0$ is not a valid value for this is undetermined for the $log(\\mathbf{\\^{y}})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)Stable Logistic Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a stable logistic loss function, we'll employ $z_2$ and the activation function (sigmoid in this case), instead of directly using $\\^y$. By injecting :\n",
    "\n",
    "$$\\^y = \\sigma(z_2) = \\frac{1}{1 + e^{-z_2}}$$\n",
    "\n",
    "Into:\n",
    "\n",
    "$$ \\mathcal{L} = -y\\cdot log\\left(\\^y\\right) -(1-y)\\cdot log\\left(1 - \\^y\\right)$$\n",
    "\n",
    "We get:\n",
    "$$ \\mathcal{L} = -y\\cdot log\\left( \\frac{1}{1 + e^{-z_2}}\\right) -(1-y)\\cdot log\\left(\\frac{e^{-z_2}}{1 + e^{-z_2}}\\right)$$\n",
    "\n",
    "With basic manipulations, we get the following final expression for the logistic loss function:\n",
    "\n",
    "$$ \\mathcal{L} = -z_2\\cdot y + log(e^{-z_2} + 1)$$\n",
    "\n",
    "Which does not have the same issue as the normal logistic function used above, as we have a stable function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_logistic_loss(y, z2):\n",
    "    # y: B x 1\n",
    "    # z2: B x 1\n",
    "    # loss: B x 1\n",
    "    B = y.shape[0]\n",
    "    loss_sum = np.sum(-y * z2 + np.logaddexp(0, z2))/B\n",
    "    return loss_sum\n",
    "\n",
    "\n",
    "z_2 = -10E10 * np.ones(10)\n",
    "y = 0 * np.ones(10)\n",
    "print(\"For z_2 = -10E10, y = 0\")\n",
    "print(\"Normal Logistic loss function :\", logistic_loss(y, sigmoid(z_2)))\n",
    "print(\"Stable Logistic loss function :\", stable_logistic_loss(y, z_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Partial Derivatives of the loss with respect to the weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is, simply put, a method of calculating partial derivatives by working backwards, from the output to the intermediary results, through the weights all up to the input. The chain rule is incredibly useful for this. Let's start with:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i} \\mathcal L(\\vec x, y, \\vec w) == \\frac{\\partial\\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial w_i^{(2)}}$$\n",
    "\n",
    "$$ \\rightarrow \\frac{\\partial \\^y}{\\partial w_i^{(2)}} = \\frac{\\partial}{\\partial w_i^{(2)}} \\left(\\frac{1}{1 + e^{-\\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{\\partial}{\\partial w_i^{(2)}} \\left(\\frac{1}{1 + e^{- w_{2,i} \\cdot  x_i^{(1)}}}\\right) = \\frac{x_i^{(1)\\cdot e^{-w_i^{(2)}x_i} }}{\\left( 1 + e^{-w_i^{(2)}x_i} \\right)^2 }$$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal L}{\\partial \\^y}  = \\frac{\\partial}{\\partial \\^y} \\left( -y\\cdot log(\\^y) -(1 - y)\\cdot log(1-\\^y) \\right) = \\frac{\\^y -y}{y\\cdot (1-\\^y)}$$\n",
    "\n",
    "Which gives us:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(2)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial w_i^{(2)}} = \\frac{\\^y -y}{y\\cdot (1-\\^y)} \\cdot \\frac{x_i^{(1)\\cdot e^{-w_i^{(2)}x_i} }}{\\left( 1 + e^{-w_i^{(2)}x_i} \\right)^2 }$$\n",
    "\n",
    "With the same logic, we can get the partial derivative of the loss with respect to the weights of the first layer:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(1)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_i^{(1)}}$$\n",
    "\n",
    "$$ \\rightarrow \\frac{\\partial \\^y}{\\partial z_2} = \\frac{\\partial}{\\partial z_2} \\left(\\frac{1}{1 + e^{-\\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{\\partial}{\\partial z_2} \\left(\\frac{1}{1 + e^{- \\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{e^{-z_2}}{\\left( 1 + e^{-z_2} \\right)^2 }$$\n",
    "\n",
    "$$ \\frac{\\partial z_2}{\\partial w_i^{(1)}} = \\frac{\\partial}{\\partial w_i^{(1)}} \\left(\\vec w_2^T \\cdot \\vec x^{(1)}\\right) = \\frac{\\partial}{\\partial w_i^{(1)}} \\left(w_{2,i} \\cdot  x_i^{(1)}\\right) = x_i^{(1)}$$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal L}{\\partial \\^y}  = \\frac{\\partial}{\\partial \\^y} \\left( -y\\cdot log(\\^y) -(1 - y)\\cdot log(1-\\^y) \\right) = \\frac{\\^y -y}{y\\cdot (1-\\^y)}$$\n",
    "\n",
    "Which gives us:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(1)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_i^{(1)}} = \\frac{\\^y -y}{y\\cdot (1-\\^y)} \\cdot \\frac{e^{-z_2}}{\\left( 1 + e^{-z_2} \\right)^2 } \\cdot x_i^{(1)}$$\n",
    "\n",
    "\n",
    "With $\\vec x^{(1)}$ being the input vector, $\\vec w_2$ being the weights of the second layer, and $\\vec w_1$ being the weights of the first layer. By replacing:\n",
    "\n",
    "$$ \\^y = \\sigma \\left( \\vec w^{(2)T}\\cdot \\sigma \\left( \\vec w^{(1)T}\\cdot \\vec x^{(0)} \\right) \\right)$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ z^{(2)} = \\vec w^{(2)T}\\cdot \\vec x^{(1)}$$ \n",
    "\n",
    "Where $\\sigma(z)$ is the sigmoid function:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Gradient Descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss_grad(X, y, W):\n",
    "    # X: B x D\n",
    "    # y: B x 1\n",
    "    # W: {w1: D x K, w2: K x 1}\n",
    "    # z1: B x K\n",
    "    # z2: B x 1\n",
    "    # yhat: B x 1\n",
    "    # grad: {w1: D x K, w2: K x 1}\n",
    "    B = X.shape[0]\n",
    "    z1, z2, yhat = predict(X, W)\n",
    "    grad = {}\n",
    "    grad['w2'] = np.dot(sigmoid(z1).T, yhat - y) / B\n",
    "    grad['w1'] = np.dot(X.T, np.dot(yhat - y, W['w2'].T) * sigmoid(z1) * (1 - sigmoid(z1))) / B\n",
    "    return grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifying FashionMNIST using neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load dataset and construct dataloader "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given in the PIL (*Python Image Library*) format. We therefore need to convert it to a type readable by the Neural Network, which is why we use *ToTensor()* transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training dataset:  60000\n",
      "Size of the testing dataset:  10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label of the first image in the training dataset:  5\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "# hyperparameters\n",
    "# 50000 images for training\n",
    "# 100 epochs\n",
    "# 10000 images for testing\n",
    "BATCH_SIZE = 2500\n",
    "TEST_BATCH_SIZE = 10000\n",
    "num_epochs = 20\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "# Construct the dataloader for the testing dataset.\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "# print the size of the training dataset\n",
    "print(\"Size of the training dataset: \", len(train_dataset))\n",
    "# print the size of the testing dataset\n",
    "print(\"Size of the testing dataset: \", len(test_dataset))\n",
    "\n",
    "# show the first image in the training dataset\n",
    "plt.imshow(train_dataset[0][0].reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "# print the label of the first image in the training dataset\n",
    "print(\"Label of the first image in the training dataset: \", train_dataset[0][1])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Multilayer Perceptron \n",
    "\n",
    "The MLP will be a simple two hidden layer, with 100 neurons per layer, rectified linear units as activation functions, and a linear output layer. 20 epochs are used for training, using the cross-entropy loss and the following optimizers:\n",
    "1. SGD with learning rate 0.01\n",
    "2. SGD with momentum 0.9, learning rate 0.01 and nesterov momentum\n",
    "3. Adam with learning rate 0.01\n",
    "4. Adam with learning rate 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the exercice sessions, we'll define the following functions:\n",
    "\n",
    "1. *train()* for training the model\n",
    "2. *test()* for testing the model\n",
    "3. *plot()* for plotting the results\n",
    "4. *predict()* for predicting the class of a given image, and prints the percentage of confidence of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # fc : fully connected, 28*28 = 784 because the images are 28x28\n",
    "        # input layer\n",
    "        self.fc0 = nn.Linear(784, 392)\n",
    "        # first hidden layer\n",
    "        self.fc1 = nn.Linear(392, 196)\n",
    "        # second hidden layer \n",
    "        self.fc2 = nn.Linear(196, 98)\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(98, 10)\n",
    "        # activation function\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        # transform the image into a vector\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        # forward pass through the layers\n",
    "        x = self.fc0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def train_epoch(\n",
    "    model : nn.Module,\n",
    "    train_loader : DataLoader,\n",
    "    optimizer : torch.optim,\n",
    "    device : torch.device,\n",
    "    epoch : int\n",
    "    ):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        # move data and target to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # compute the loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        # print statistics information\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader.dataset)\n",
    "\n",
    "def fit(\n",
    "    model : nn.Module,\n",
    "    train_loader : DataLoader,\n",
    "    optimizer : torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device : torch.device\n",
    "    ):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        current_loss = train_epoch( model,\n",
    "                                    train_loader, \n",
    "                                    optimizer, \n",
    "                                    device, \n",
    "                                    epoch)\n",
    "        print(f\"Epoch {epoch} loss: {current_loss}\")\n",
    "        losses.append(current_loss)\n",
    "    return losses\n",
    "\n",
    "def predict(\n",
    "            model : nn.Module,\n",
    "            test_loader : DataLoader,\n",
    "            device : torch.device\n",
    "            ):\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # compute the loss\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            test_loss += loss.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\")\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = neural_network()\n",
    "# move the model to the GPU/CPU according to availability\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# create optimizers\n",
    "SGD_optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "SGD_momentum_optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "Adam_optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "Adam2_optimizer = torch.optim.Adam(model.parameters(), lr=1)\n",
    "\n",
    "# sanity check \n",
    "predict(model, test_dataloader, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up and we performed a sanity check, we can train the 20 epochs for each optimizer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"Training the model\")\n",
    "print(\"Optimizer: SGD\")\n",
    "SGD_losses = fit(model, train_dataloader, SGD_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: SGD with momentum\")\n",
    "SGD_momentum_losses = fit(model, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam\")\n",
    "Adam_losses = fit(model, train_dataloader, Adam_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam2\")\n",
    "Adam2_losses = fit(model, train_dataloader, Adam2_optimizer, num_epochs, DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the losses on 4 different graphs\n",
    "fig,ax = plt.subplots(2,2, figsize=(15,10))\n",
    "ax[0,0].plot(SGD_losses)\n",
    "ax[0,0].set_title(\"SGD\")\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_xlabel(\"Epochs\")\n",
    "ax[0,1].plot(SGD_momentum_losses)\n",
    "ax[0,1].set_title(\"SGD with momentum\")\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_xlabel(\"Epochs\")\n",
    "ax[1,0].plot(Adam_losses)\n",
    "ax[1,0].set_title(\"Adam\")\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_xlabel(\"Epochs\")\n",
    "ax[1,1].plot(Adam2_losses)\n",
    "ax[1,1].set_title(\"Adam2\")\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can see that the Adam optimizer with learning rate 1 performs the best, with a test accuracy of 86.5%. The Adam optimizer with learning rate 0.01 performs the worst, with a test accuracy of 84.5%. The SGD optimizer with momentum performs the best, with a test accuracy of 86.5%. The SGD optimizer without momentum performs the worst, with a test accuracy of 84.5%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convolution Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to construct a CNN with the following architecture:\n",
    "\n",
    "- 3 convolutional layers with 16, 32 and 64 channels.\n",
    "- a non-linearity layer and a max pooling layer after each convolutional layer.\n",
    "- a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # first convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 1, \n",
    "                out_channels = 16, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # second convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 32,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # third convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 64,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_out = nn.Linear(64*3*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model for 20 epochs, using the same optimizers as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(DEVICE)\n",
    "# create optimizers\n",
    "SGD_optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "SGD_momentum_optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "Adam_optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
    "Adam2_optimizer = torch.optim.Adam(cnn.parameters(), lr=1)\n",
    "\n",
    "# sanity check\n",
    "predict(cnn, test_dataloader, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"Training the model\")\n",
    "print(\"Optimizer: SGD\")\n",
    "SGD_cnn_losses = fit(cnn, train_dataloader, SGD_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: SGD with momentum\")\n",
    "SGD_cnn_momentum_losses = fit(cnn, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam\")\n",
    "Adam_cnn_losses = fit(cnn, train_dataloader, Adam_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam2\")\n",
    "Adam2_cnn_losses = fit(cnn, train_dataloader, Adam2_optimizer, num_epochs, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses on 4 different graphs\n",
    "fig,ax = plt.subplots(2,2, figsize=(15,10))\n",
    "ax[0,0].plot(SGD_cnn_losses)\n",
    "ax[0,0].set_title(\"SGD\")\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_xlabel(\"Epochs\")\n",
    "ax[0,1].plot(SGD_cnn_momentum_losses)\n",
    "ax[0,1].set_title(\"SGD with momentum\")\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_xlabel(\"Epochs\")\n",
    "ax[1,0].plot(Adam_cnn_losses)\n",
    "ax[1,0].set_title(\"Adam\")\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_xlabel(\"Epochs\")\n",
    "ax[1,1].plot(Adam2_cnn_losses)\n",
    "ax[1,1].set_title(\"Adam2\")\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Hyperparameter analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we aim to analyse the number of hyperparameters of the MLP and CNN models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that computes the number of parameters of a given model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Number of parameters of the MLP: \", count_parameters(model))\n",
    "print(\"Number of parameters of the CNN: \", count_parameters(cnn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that FINIR CA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Permutted Fashion MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPermutation(object):\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.reindex = torch.randperm(num_features)\n",
    "    def __call__(self, img):\n",
    "        assert self.num_features == img.numel()\n",
    "        orig_shape = img.shape\n",
    "        img = img.view(-1)[self.reindex].view(orig_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "rand_train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=RandomPermutation(28*28)\n",
    "    )\n",
    "\n",
    "rand_test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=RandomPermutation(28*28)\n",
    ")\n",
    "\n",
    "rand_train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "rand_test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# CNN with random permutation\n",
    "print(\"Training the CNN model with random permutation\")\n",
    "SGD_rand_cnn = fit(cnn, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "# MLP with random permutation\n",
    "print(\"Training the MLP model with random permutation\")\n",
    "SGD_rand_mlp = fit(model, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "\n",
    "# plot the losses on 2 different graphs\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].plot(SGD_rand_cnn)\n",
    "ax[0].set_title(\"CNN\")\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[1].plot(SGD_rand_mlp)\n",
    "ax[1].set_title(\"MLP\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Multi-Task Learning with MultiMNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create a new sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "#print first image\n",
    "print(train_dataset[0][0].shape)\n",
    "plt.imshow(train_dataset[0][0].reshape(28,28), cmap='gray')\n",
    "plt.show()\n",
    "print(train_dataset[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "5\n",
      "torch.Size([1, 28, 28])\n",
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 5)\n"
     ]
    }
   ],
   "source": [
    "# print train_dataset type\n",
    "print(type(train_dataset))\n",
    "# print first image label\n",
    "print(train_dataset[0][1])\n",
    "# print first data shape\n",
    "print(train_dataset[0][0].shape)\n",
    "# print first data sample shape\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data format is as follows:\n",
    "\n",
    "  *train_dataset[x][y]*\n",
    "\n",
    "Where x is the index of the sample, and y is the index of the element of the sample.\n",
    "The first element of the sample is the image, and the second element is the label. Therefore, the new data set must have three elements: the image data, the first label and the second label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# get two images of 28x28 from the test dataset\n",
    "# create a new sample of 36x36 with the two images, one on the top left corner and the other on the bottom right corner\n",
    "def make_new_sample(x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # create a new sample\n",
    "    # create a new sample of 36x36\n",
    "    x = torch.zeros(1, 36, 36)\n",
    "    y = torch.zeros(1, 36, 36)\n",
    "    # put the first image on the top left corner\n",
    "    x[:, :28, :28] = x1[0]\n",
    "    # put the second image on the bottom right corner\n",
    "    y[:, 8:, 8:] = x2[0]\n",
    "    # return the new sample\n",
    "    return torch.maximum(x, y)\n",
    "    \n",
    "    \n",
    "# get random samples from the train dataset\n",
    "x1, y1 = next(iter(train_dataloader))\n",
    "x2, y2 = next(iter(train_dataloader))\n",
    "# create a new sample\n",
    "new_sample = make_new_sample(x1, x2)\n",
    "\n",
    "# show the two images\n",
    "fig,ax = plt.subplots(1,3, figsize=(5,5))\n",
    "ax[0].imshow(x1[0].squeeze(), cmap='gray')\n",
    "ax[0].set_title(\"First Image: \" + str(y1[0].item()))\n",
    "ax[1].imshow(x2[0].squeeze(), cmap='gray')\n",
    "ax[1].set_title(\"Second image: \"+ str(y2[0].item()))\n",
    "ax[2].imshow(new_sample[0].squeeze(), cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create a the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 6000\n",
    "TEST_BATCH_SIZE = 1000\n",
    "EPOCHS = 10\n",
    "#put image in the upper left corner is the first image, bottom right corner is the second image\n",
    "\n",
    "new_trainset = []\n",
    "new_testset = []\n",
    "\n",
    "for i in range(60000):\n",
    "    x1,y1 = train_dataset[torch.randint(len(train_dataset), size=(1,)).item()][:]\n",
    "    x2,y2 = train_dataset[torch.randint(len(train_dataset), size=(1,)).item()][:]\n",
    "    new_trainset.append([make_new_sample(x1, x2), y1, y2])\n",
    "\n",
    "for i in range(10000):\n",
    "    x1,y1 = test_dataset[torch.randint(len(test_dataset), size=(1,)).item()][:]\n",
    "    x2,y2= test_dataset[torch.randint(len(test_dataset), size=(1,)).item()][:]\n",
    "    new_testset.append([make_new_sample(x1, x2), y1, y2])\n",
    "\n",
    "# show random samples from new_trainset\n",
    "fig,ax = plt.subplots(2,3, figsize=(5,4))\n",
    "# trainset\n",
    "print(new_trainset[0][1], new_trainset[0][2])\n",
    "ax[0,0].imshow(new_trainset[0][0].squeeze(), cmap='gray')\n",
    "ax[0,1].imshow(new_trainset[1][0].squeeze(), cmap='gray')\n",
    "ax[0,2].imshow(new_trainset[2][0].squeeze(), cmap='gray')\n",
    "# testset\n",
    "ax[1,0].imshow(new_testset[0][0].squeeze(), cmap='gray')\n",
    "ax[1,1].imshow(new_testset[1][0].squeeze(), cmap='gray')\n",
    "ax[1,2].imshow(new_testset[2][0].squeeze(), cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "# create the new train and test dataloaders\n",
    "\n",
    "new_train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=new_trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "new_test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=new_testset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader shape:  torch.Size([6000, 1, 36, 36])\n",
      "Test dataloader shape:  torch.Size([1000, 1, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new train and test dataloaders\n",
    "print(\"Train dataloader shape: \", next(iter(new_train_dataloader)).shape)\n",
    "print(\"Test dataloader shape: \", next(iter(new_test_dataloader)).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create the Multi Task Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a CNN with the following architecture:\n",
    "- Encoder :\n",
    "    - 2 convolution layers of 10 and 20 channels\n",
    "    - A liner layer of 50 neurons\n",
    "    - Each convolution layer has kernel size of 5, followed by ReLU activation and max pooling layer\n",
    "- Decoder : each decoder is a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new model\n",
    "# encoder has two convolution layers of 10 and 20 channels, a linear layer with 50 output .\n",
    "# each convolutional layer has kernel site of 5 and is followed by relu and maxpool. \n",
    "# each decoder is a linear layer with 20*4*4 input and 20*4*4 output, followed by a convolutional layer of 10 channels, relu and maxpool.\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(10, 20, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(720, 50)            \n",
    "            \n",
    "        )\n",
    "        # first decoder, \n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        # second decoder\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x1 = self.decoder1(x)\n",
    "        x2 = self.decoder2(x)\n",
    "        return x1, x2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# create the new model\n",
    "model = Autoencoder()\n",
    "# move the model to the GPU\n",
    "model = model.to(device)\n",
    "# create the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Train the Multi Task Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here we need to adapt the training and predict funsions seen in class to handle two predictions, two losses, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader shape:  torch.Size([6000, 1, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "#print the data\n",
    "print(\"Train dataloader shape: \", next(iter(new_train_dataloader)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([6000, 1]) torch.Size([6000, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"mse_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, new_train_dataloader, optimizer, criterion, device)\n\u001b[0;32m     53\u001b[0m     test_loss, test_accuracy1, test_accuracy2 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m , \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m \u001b[39m#test(model, new_test_dataloader, criterion, device)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTraining Loss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Loss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Accuracy1: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Accuracy2: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     55\u001b[0m         epoch, train_loss, test_loss, test_accuracy1, test_accuracy2))\n",
      "Cell \u001b[1;32mIn [12], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(target1), \u001b[39mtype\u001b[39m(index_output1))\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(index_output1\u001b[39m.\u001b[39mshape, target1\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 21\u001b[0m loss1 \u001b[39m=\u001b[39m criterion(index_output1, target1)\n\u001b[0;32m     22\u001b[0m loss2 \u001b[39m=\u001b[39m criterion(index_output2, target2)\n\u001b[0;32m     24\u001b[0m loss \u001b[39m=\u001b[39m (loss1 \u001b[39m+\u001b[39m loss2)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3292\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(\u001b[39minput\u001b[39m, target)\n\u001b[1;32m-> 3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"mse_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "# train the multi tas model and report the accuracy and loss per task\n",
    "# use the average of task loss as objective. Adapt the training and prediction functions from the previous section\n",
    "# to handle two predictions and two losses\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target1, target2) in enumerate(train_loader):\n",
    "        \n",
    "        #data, target1, target2 = data.to(device), target1.to(device), target2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(data)\n",
    "        index_output1 = output1.argmax(dim=1, keepdim=True)\n",
    "        index_output2 = output2.argmax(dim=1, keepdim=True)\n",
    "        # reshape the targets to match the output shape\n",
    "        target1 = target1.view_as(index_output1)\n",
    "        target2 = target2.view_as(index_output2)\n",
    "        print(type(target1[0]), type(index_output1[0]))\n",
    "        print(index_output1.shape, target1.shape)\n",
    "        loss1 = criterion(index_output1, target1)\n",
    "        loss2 = criterion(index_output2, target2)\n",
    "\n",
    "        loss = (loss1 + loss2)/2\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct1 = 0\n",
    "    correct2 = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target1, target2 in test_loader:\n",
    "            data, target1, target2 = data.to(device), target1.to(device), target2.to(device)\n",
    "            output1, output2 = model(data)\n",
    "            test_loss += criterion(output1, target1).item() + criterion(output2, target2).item() # sum up batch loss\n",
    "            pred1 = output1.argmax(dim=1) # get the index of the max log-probability\n",
    "            pred2 = output2.argmax(dim=1) # get the index of the max log-probability\n",
    "            correct1 += pred1.eq(target1.view_as(pred1)).sum().item()\n",
    "            correct2 += pred2.eq(target2.view_as(pred2)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy1 = 100. * correct1 / len(test_loader.dataset)\n",
    "    test_accuracy2 = 100. * correct2 / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy1, test_accuracy2\n",
    "\n",
    "# train the model\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train(model, new_train_dataloader, optimizer, criterion, device)\n",
    "    test_loss, test_accuracy1, test_accuracy2 = 0 , 0, 0 #test(model, new_test_dataloader, criterion, device)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTest Accuracy1: {:.2f}% \\tTest Accuracy2: {:.2f}%'.format(\n",
    "        epoch, train_loss, test_loss, test_accuracy1, test_accuracy2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9566ee846e0e5475f3731207e71ee4a96d604221359f666805a9fa43f54da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
