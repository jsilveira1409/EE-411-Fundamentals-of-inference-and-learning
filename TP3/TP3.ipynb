{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE-411, HomeWork 3 : Neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backpropagation with logistic loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = 5\n",
    "K = 6\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def predict(X, W):\n",
    "    # X: B x D\n",
    "    # W: {w1: D x K, w2: K x 1}\n",
    "    # z1: B x K\n",
    "    # z2: B x 1\n",
    "    # yhat: B x 1\n",
    "    z1 = np.dot(X, W['w1'])\n",
    "    x1 = sigmoid(z1)\n",
    "    z2 = np.dot(x1, W['w2'])\n",
    "    yhat = sigmoid(z2)\n",
    "    return z1, z2, yhat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)Logistic Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logistic_loss(y, yhat):\n",
    "    # y: B x 1\n",
    "    # yhat: B x 1\n",
    "    # loss: B x 1\n",
    "    B = y.shape[0]\n",
    "    loss_sum = np.sum(-y * np.log(yhat) - (1 - y) * np.log(1 - yhat)) / B\n",
    "    return loss_sum\n",
    "\n",
    "\n",
    "# testing with yhat =  y -> 0, not possible to compute log(0)\n",
    "y = np.ones(10)    * 0.000000000000000\n",
    "yhat = np.ones(10) * 0.000000000000000001\n",
    "print(logistic_loss(y, yhat))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\mathbf y \\simeq \\mathbf{\\^{y}} \\simeq 0$, we get an average logistic loss of nearly 0 for the whole batch. This is expected, as the expected value and the ground truth are equal. However, $0$ is not a valid value for this is undetermined for the $log(\\mathbf{\\^{y}})$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)Stable Logistic Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a stable logistic loss function, we'll employ $z_2$ and the activation function (sigmoid in this case), instead of directly using $\\^y$. By injecting :\n",
    "\n",
    "$$\\^y = \\sigma(z_2) = \\frac{1}{1 + e^{-z_2}}$$\n",
    "\n",
    "Into:\n",
    "\n",
    "$$ \\mathcal{L} = -y\\cdot log\\left(\\^y\\right) -(1-y)\\cdot log\\left(1 - \\^y\\right)$$\n",
    "\n",
    "We get:\n",
    "$$ \\mathcal{L} = -y\\cdot log\\left( \\frac{1}{1 + e^{-z_2}}\\right) -(1-y)\\cdot log\\left(\\frac{e^{-z_2}}{1 + e^{-z_2}}\\right)$$\n",
    "\n",
    "With basic manipulations, we get the following final expression for the logistic loss function:\n",
    "\n",
    "$$ \\mathcal{L} = -z_2\\cdot y + log(e^{-z_2} + 1)$$\n",
    "\n",
    "Which does not have the same issue as the normal logistic function used above, as we have a stable function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_logistic_loss(y, z2):\n",
    "    # y: B x 1\n",
    "    # z2: B x 1\n",
    "    # loss: B x 1\n",
    "    B = y.shape[0]\n",
    "    loss_sum = np.sum(-y * z2 + np.logaddexp(0, z2))/B\n",
    "    return loss_sum\n",
    "\n",
    "\n",
    "z_2 = -10E10 * np.ones(10)\n",
    "y = 0 * np.ones(10)\n",
    "print(\"For z_2 = -10E10, y = 0\")\n",
    "print(\"Normal Logistic loss function :\", logistic_loss(y, sigmoid(z_2)))\n",
    "print(\"Stable Logistic loss function :\", stable_logistic_loss(y, z_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Partial Derivatives of the loss with respect to the weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is, simply put, a method of calculating partial derivatives by working backwards, from the output to the intermediary results, through the weights all up to the input. The chain rule is incredibly useful for this. Let's start with:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i} \\mathcal L(\\vec x, y, \\vec w) == \\frac{\\partial\\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial w_i^{(2)}}$$\n",
    "\n",
    "$$ \\rightarrow \\frac{\\partial \\^y}{\\partial w_i^{(2)}} = \\frac{\\partial}{\\partial w_i^{(2)}} \\left(\\frac{1}{1 + e^{-\\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{\\partial}{\\partial w_i^{(2)}} \\left(\\frac{1}{1 + e^{- w_{2,i} \\cdot  x_i^{(1)}}}\\right) = \\frac{x_i^{(1)\\cdot e^{-w_i^{(2)}x_i} }}{\\left( 1 + e^{-w_i^{(2)}x_i} \\right)^2 }$$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal L}{\\partial \\^y}  = \\frac{\\partial}{\\partial \\^y} \\left( -y\\cdot log(\\^y) -(1 - y)\\cdot log(1-\\^y) \\right) = \\frac{\\^y -y}{y\\cdot (1-\\^y)}$$\n",
    "\n",
    "Which gives us:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(2)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial w_i^{(2)}} = \\frac{\\^y -y}{y\\cdot (1-\\^y)} \\cdot \\frac{x_i^{(1)\\cdot e^{-w_i^{(2)}x_i} }}{\\left( 1 + e^{-w_i^{(2)}x_i} \\right)^2 }$$\n",
    "\n",
    "With the same logic, we can get the partial derivative of the loss with respect to the weights of the first layer:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(1)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_i^{(1)}}$$\n",
    "\n",
    "$$ \\rightarrow \\frac{\\partial \\^y}{\\partial z_2} = \\frac{\\partial}{\\partial z_2} \\left(\\frac{1}{1 + e^{-\\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{\\partial}{\\partial z_2} \\left(\\frac{1}{1 + e^{- \\vec w_2^T \\cdot \\vec x^{(1)}}}\\right) = \\frac{e^{-z_2}}{\\left( 1 + e^{-z_2} \\right)^2 }$$\n",
    "\n",
    "$$ \\frac{\\partial z_2}{\\partial w_i^{(1)}} = \\frac{\\partial}{\\partial w_i^{(1)}} \\left(\\vec w_2^T \\cdot \\vec x^{(1)}\\right) = \\frac{\\partial}{\\partial w_i^{(1)}} \\left(w_{2,i} \\cdot  x_i^{(1)}\\right) = x_i^{(1)}$$\n",
    "\n",
    "$$ \\frac{\\partial \\mathcal L}{\\partial \\^y}  = \\frac{\\partial}{\\partial \\^y} \\left( -y\\cdot log(\\^y) -(1 - y)\\cdot log(1-\\^y) \\right) = \\frac{\\^y -y}{y\\cdot (1-\\^y)}$$\n",
    "\n",
    "Which gives us:\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w_i^{(1)}} \\mathcal L(\\vec x, y, \\vec w) = \\frac{\\partial \\mathcal L}{\\partial \\^y} \\cdot \\frac{\\partial \\^y}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_i^{(1)}} = \\frac{\\^y -y}{y\\cdot (1-\\^y)} \\cdot \\frac{e^{-z_2}}{\\left( 1 + e^{-z_2} \\right)^2 } \\cdot x_i^{(1)}$$\n",
    "\n",
    "\n",
    "With $\\vec x^{(1)}$ being the input vector, $\\vec w_2$ being the weights of the second layer, and $\\vec w_1$ being the weights of the first layer. By replacing:\n",
    "\n",
    "$$ \\^y = \\sigma \\left( \\vec w^{(2)T}\\cdot \\sigma \\left( \\vec w^{(1)T}\\cdot \\vec x^{(0)} \\right) \\right)$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ z^{(2)} = \\vec w^{(2)T}\\cdot \\vec x^{(1)}$$ \n",
    "\n",
    "Where $\\sigma(z)$ is the sigmoid function:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Gradient Descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss_grad(X, y, W):\n",
    "    # X: B x D\n",
    "    # y: B x 1\n",
    "    # W: {w1: D x K, w2: K x 1}\n",
    "    # z1: B x K\n",
    "    # z2: B x 1\n",
    "    # yhat: B x 1\n",
    "    # grad: {w1: D x K, w2: K x 1}\n",
    "    B = X.shape[0]\n",
    "    z1, z2, yhat = predict(X, W)\n",
    "    grad = {}\n",
    "    grad['w2'] = np.dot(sigmoid(z1).T, yhat - y) / B\n",
    "    grad['w1'] = np.dot(X.T, np.dot(yhat - y, W['w2'].T) * sigmoid(z1) * (1 - sigmoid(z1))) / B\n",
    "    return grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifying FashionMNIST using neural networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load dataset and construct dataloader "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is given in the PIL (*Python Image Library*) format. We therefore need to convert it to a type readable by the Neural Network, which is why we use *ToTensor()* transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "# hyperparameters\n",
    "# 50000 images for training\n",
    "# 100 epochs\n",
    "# 10000 images for testing\n",
    "BATCH_SIZE = 2500\n",
    "TEST_BATCH_SIZE = 10000\n",
    "num_epochs = 20\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "# Construct the dataloader for the testing dataset.\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Multilayer Perceptron \n",
    "\n",
    "The MLP will be a simple two hidden layer, with 100 neurons per layer, rectified linear units as activation functions, and a linear output layer. 20 epochs are used for training, using the cross-entropy loss and the following optimizers:\n",
    "1. SGD with learning rate 0.01\n",
    "2. SGD with momentum 0.9, learning rate 0.01 and nesterov momentum\n",
    "3. Adam with learning rate 0.01\n",
    "4. Adam with learning rate 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the exercice sessions, we'll define the following functions:\n",
    "\n",
    "1. *train()* for training the model\n",
    "2. *test()* for testing the model\n",
    "3. *plot()* for plotting the results\n",
    "4. *predict()* for predicting the class of a given image, and prints the percentage of confidence of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # fc : fully connected, 28*28 = 784 because the images are 28x28\n",
    "        # input layer\n",
    "        self.fc0 = nn.Linear(784, 392)\n",
    "        # first hidden layer\n",
    "        self.fc1 = nn.Linear(392, 196)\n",
    "        # second hidden layer \n",
    "        self.fc2 = nn.Linear(196, 98)\n",
    "        # output layer\n",
    "        self.fc3 = nn.Linear(98, 10)\n",
    "        # activation function\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x : torch.Tensor) -> torch.Tensor:\n",
    "        # transform the image into a vector\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        # forward pass through the layers\n",
    "        x = self.fc0(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def train_epoch(\n",
    "    model : nn.Module,\n",
    "    train_loader : DataLoader,\n",
    "    optimizer : torch.optim,\n",
    "    device : torch.device,\n",
    "    epoch : int\n",
    "    ):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        # move data and target to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # compute the loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        # print statistics information\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader.dataset)\n",
    "\n",
    "def fit(\n",
    "    model : nn.Module,\n",
    "    train_loader : DataLoader,\n",
    "    optimizer : torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device : torch.device\n",
    "    ):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        current_loss = train_epoch( model,\n",
    "                                    train_loader, \n",
    "                                    optimizer, \n",
    "                                    device, \n",
    "                                    epoch)\n",
    "        print(f\"Epoch {epoch} loss: {current_loss}\")\n",
    "        losses.append(current_loss)\n",
    "    return losses\n",
    "\n",
    "def predict(\n",
    "            model : nn.Module,\n",
    "            test_loader : DataLoader,\n",
    "            device : torch.device\n",
    "            ):\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass\n",
    "            output = model(data)\n",
    "            # compute the loss\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            test_loss += loss.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\")\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = neural_network()\n",
    "# move the model to the GPU/CPU according to availability\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# create optimizers\n",
    "SGD_optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "SGD_momentum_optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "Adam_optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "Adam2_optimizer = torch.optim.Adam(model.parameters(), lr=1)\n",
    "\n",
    "# sanity check \n",
    "predict(model, test_dataloader, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is set up and we performed a sanity check, we can train the 20 epochs for each optimizer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"Training the model\")\n",
    "print(\"Optimizer: SGD\")\n",
    "SGD_losses = fit(model, train_dataloader, SGD_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: SGD with momentum\")\n",
    "SGD_momentum_losses = fit(model, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam\")\n",
    "Adam_losses = fit(model, train_dataloader, Adam_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam2\")\n",
    "Adam2_losses = fit(model, train_dataloader, Adam2_optimizer, num_epochs, DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the losses on 4 different graphs\n",
    "fig,ax = plt.subplots(2,2, figsize=(15,10))\n",
    "ax[0,0].plot(SGD_losses)\n",
    "ax[0,0].set_title(\"SGD\")\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_xlabel(\"Epochs\")\n",
    "ax[0,1].plot(SGD_momentum_losses)\n",
    "ax[0,1].set_title(\"SGD with momentum\")\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_xlabel(\"Epochs\")\n",
    "ax[1,0].plot(Adam_losses)\n",
    "ax[1,0].set_title(\"Adam\")\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_xlabel(\"Epochs\")\n",
    "ax[1,1].plot(Adam2_losses)\n",
    "ax[1,1].set_title(\"Adam2\")\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can see that the Adam optimizer with learning rate 1 performs the best, with a test accuracy of 86.5%. The Adam optimizer with learning rate 0.01 performs the worst, with a test accuracy of 84.5%. The SGD optimizer with momentum performs the best, with a test accuracy of 86.5%. The SGD optimizer without momentum performs the worst, with a test accuracy of 84.5%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convolution Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to construct a CNN with the following architecture:\n",
    "\n",
    "- 3 convolutional layers with 16, 32 and 64 channels.\n",
    "- a non-linearity layer and a max pooling layer after each convolutional layer.\n",
    "- a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # first convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 1, \n",
    "                out_channels = 16, \n",
    "                kernel_size=3, \n",
    "                stride=1, \n",
    "                padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # second convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 16,\n",
    "                out_channels = 32,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # third convolution layer\n",
    "            nn.Conv2d(\n",
    "                in_channels = 32,\n",
    "                out_channels = 64,\n",
    "                kernel_size = 3,\n",
    "                stride = 1,\n",
    "                padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_out = nn.Linear(64*3*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model for 20 epochs, using the same optimizers as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN().to(DEVICE)\n",
    "# create optimizers\n",
    "SGD_optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "SGD_momentum_optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "Adam_optimizer = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
    "Adam2_optimizer = torch.optim.Adam(cnn.parameters(), lr=1)\n",
    "\n",
    "# sanity check\n",
    "predict(cnn, test_dataloader, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print(\"Training the model\")\n",
    "print(\"Optimizer: SGD\")\n",
    "SGD_cnn_losses = fit(cnn, train_dataloader, SGD_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: SGD with momentum\")\n",
    "SGD_cnn_momentum_losses = fit(cnn, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam\")\n",
    "Adam_cnn_losses = fit(cnn, train_dataloader, Adam_optimizer, num_epochs, DEVICE)\n",
    "print(\"Optimizer: Adam2\")\n",
    "Adam2_cnn_losses = fit(cnn, train_dataloader, Adam2_optimizer, num_epochs, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses on 4 different graphs\n",
    "fig,ax = plt.subplots(2,2, figsize=(15,10))\n",
    "ax[0,0].plot(SGD_cnn_losses)\n",
    "ax[0,0].set_title(\"SGD\")\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_xlabel(\"Epochs\")\n",
    "ax[0,1].plot(SGD_cnn_momentum_losses)\n",
    "ax[0,1].set_title(\"SGD with momentum\")\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_xlabel(\"Epochs\")\n",
    "ax[1,0].plot(Adam_cnn_losses)\n",
    "ax[1,0].set_title(\"Adam\")\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_xlabel(\"Epochs\")\n",
    "ax[1,1].plot(Adam2_cnn_losses)\n",
    "ax[1,1].set_title(\"Adam2\")\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Hyperparameter analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we aim to analyse the number of hyperparameters of the MLP and CNN models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that computes the number of parameters of a given model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Number of parameters of the MLP: \", count_parameters(model))\n",
    "print(\"Number of parameters of the CNN: \", count_parameters(cnn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that FINIR CA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Permutted Fashion MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPermutation(object):\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.reindex = torch.randperm(num_features)\n",
    "    def __call__(self, img):\n",
    "        assert self.num_features == img.numel()\n",
    "        orig_shape = img.shape\n",
    "        img = img.view(-1)[self.reindex].view(orig_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "rand_train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=RandomPermutation(28*28)\n",
    "    )\n",
    "\n",
    "rand_test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=RandomPermutation(28*28)\n",
    ")\n",
    "\n",
    "rand_train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "rand_test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# CNN with random permutation\n",
    "print(\"Training the CNN model with random permutation\")\n",
    "SGD_rand_cnn = fit(cnn, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "# MLP with random permutation\n",
    "print(\"Training the MLP model with random permutation\")\n",
    "SGD_rand_mlp = fit(model, train_dataloader, SGD_momentum_optimizer, num_epochs, DEVICE)\n",
    "\n",
    "# plot the losses on 2 different graphs\n",
    "fig,ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].plot(SGD_rand_cnn)\n",
    "ax[0].set_title(\"CNN\")\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[1].plot(SGD_rand_mlp)\n",
    "ax[1].set_title(\"MLP\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Multi-Task Learning with MultiMNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create a new sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=transform)\n",
    "\n",
    "# get two images of 28x28 from the test dataset\n",
    "# create a new sample of 36x36 with the two images, one on the top left corner and the other on the bottom right corner\n",
    "def make_new_sample(x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "    # create a new sample of 36x36\n",
    "    x = torch.zeros(1, 36, 36)\n",
    "    y = torch.zeros(1, 36, 36)\n",
    "    # put the first image on the top left corner\n",
    "    x[:, :28, :28] = x1[0]\n",
    "    # put the second image on the bottom right corner\n",
    "    y[:, 8:, 8:] = x2[0]\n",
    "    return torch.maximum(x, y)\n",
    "# get random samples from the train dataset\n",
    "x1, y1 = next(iter(train_dataloader))\n",
    "x2, y2 = next(iter(train_dataloader))\n",
    "# show the two images\n",
    "fig,ax = plt.subplots(1,3, figsize=(5,5))\n",
    "ax[0].imshow(x1[0].squeeze(), cmap='gray')\n",
    "ax[0].set_title(\"First Image: \" + str(y1[0].item()))\n",
    "ax[1].imshow(x2[0].squeeze(), cmap='gray')\n",
    "ax[1].set_title(\"Second image: \"+ str(y2[0].item()))\n",
    "ax[2].imshow(make_new_sample(x1, x2).squeeze(), cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create a the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFiCAYAAAA5jpuPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7Q0lEQVR4nO3df1hUVf4H8LcYjJYwiAZEOmplqbm2GytKVmtKkbZtJvY7ra00DW3VsqJdt+2HS1/7oWam7X4NrdYvZYWuZqlh6lqYSVkhSVm2UghlBYO/gOB+//DxdM51ZrrD3Jk5zLxfzzPP87lzz9w5Dh85zDn3nNPOMAwDREREpKWYcFeAiIiIvGNDTUREpDE21ERERBpjQ01ERKQxNtREREQaY0NNRESkMTbUREREGmNDTUREpDE21ERERBpjQ01ERKSxoDXUCxYsQM+ePdGhQwcMGjQI27ZtC9ZbEXnEHCQdMA8pUO2Csdb3Sy+9hHHjxmHRokUYNGgQ5s6di+XLl6OiogLJyck+X9vS0oKqqirEx8ejXbt2dleNwswwDNTX1yMtLQ0xMcHr0AkkBwHmYSQLVQ4CzEPyzq88NIIgIyPDyM3NFcfNzc1GWlqakZ+f/4uvraysNADwEeGPysrKYKSeEEgOGgbzMBoewc5Bw2Ae8mFPHtr+52RjYyNKS0uRlZUlnouJiUFWVhZKSkqOK9/Q0AC32y0eBjfzigrx8fFBu7a/OQgwD6NRMHMQYB6SNVby0PaGev/+/WhubkZKSoryfEpKCqqrq48rn5+fD6fTKR4ul8vuKpGGgtmN528OAszDaBTsrmTmIVlhJQ/Dftd3Xl4e6urqxKOysjLcVaIoxDwkHTAPyZMT7L5g165d0b59e9TU1CjP19TUIDU19bjyDocDDofD7mpQFPM3BwHmIdmPeUh2sf0bdVxcHNLT01FcXCyea2lpQXFxMTIzM+1+O6LjMAdJB8xDsk3r7mX0rbCw0HA4HMaSJUuM8vJyY8KECUZiYqJRXV39i6+tq6sL+114fAT/UVdXF4zUsyUHmYfR8Qh2DhoG85APe/IwKA21YRjG/PnzDZfLZcTFxRkZGRnG1q1bLb2OiRkdj1D8kmxtDhoG8zAaHqHIQcNgHvIReB4GZcGTQLjdbjidznBXg4Ksrq4OCQkJ4a6GV8zDyKd7DgLMw2hgJQ9tv5mMiIJn4sSJIl6wYIGITznlFKXcjz/+KOIuXbqI+Pvvv1fKNTU12V1FIrJZ2KdnERERkXdsqImIiDTGrm8ijV100UXK8SOPPCJi+faSPXv2KOXkKUEjR44U8euvv66UGzdunIh79uwp4r179yrl5K50IgotfqMmIiLSGBtqIiIijbGhJiIi0hjHqIk0079/fxHPnj1bOZeYmOjxNR06dFCO5XFp2WWXXaYcFxUVifh3v/udiN9++22lnFwPeYvG+vp6j+9D0WPAgAEiXrlypXLuhBN+bmLkZVO//vrr4FcsgvAbNRERkcbYUBMREWmMS4jarHPnziIeMmSIpdf069dPxMOHDw+4Dg8//LCIt2zZEvD1gkH35RtDnYfy6mEVFRUi9tbVbWbefL41/63la/h6/a9//WsRl5WV+f0+utA9BwF9fx/GxsaK+NVXXxXxJZdcopSLi4sT8f/8z/+IOC8vL4i1a1us5CG/URMREWmMDTUREZHGeNe3RfLdi2eddZaIZ86cqZS78MILRZyamhr8inkwePBgEevYbUbHk7sSrXZ3yx5//HGv57766isR79q1Szl36aWXivjuu++29F5PP/20iM13kR88eNDSNahtu/HGG0X8+9//XsSzZs1SyslDeaeddlrwKxah+I2aiIhIY2yoiYiINMaGmoiISGMco/biuuuuU44feOABEZ955pm2vldtba2Iv/nmG+XcSSedJGJ5dyNfmpqa7KgWhZC8Kpg8TaqxsVEp984774j4iiuuEHFrx4blFcgeeughET/44INKuWnTpon4ggsuEPGMGTOUcn/7299aVQ/SW48ePZTjZ555RsRyDpnz5pNPPhHxokWLglQ73zIyMkQ8duxY5dwHH3wg4oKCgpDVyV/8Rk1ERKQxNtREREQaY9e3F+bNEE499VSP5czdzKtXr/ZY7tChQ8rxc889J+J9+/aJ+L///a9S7oUXXhCx1a7vq666ylI50oc85PHRRx+JeP78+Uq5YHbPyd3nTz75pHLuyiuvFLHcDSpP/aLIIq8qlp+fr5zbv3+/iOWpWj/99JPX68nd4Hbo06ePiEeNGqWcGzNmjIi///57EZunMW7YsMHWOgULv1ETERFpzO+GevPmzbj88suRlpaGdu3aYcWKFcp5wzDw17/+Faeccgo6duyIrKwsfP7553bVl4g5SFpgHlKo+N31ffDgQZxzzjm45ZZbMHr06OPOz549G0899RSWLl2KXr16YebMmcjOzkZ5eflxe+bq5vTTTxdxfHy8cq6lpUXE8h3gchc2oHZj+9K+fXsR/+Y3vxHxZ599ppTz1uUudz0Batfke++9Z6kObVUk5qC8ecq5554bljrIsxn+8Ic/KOfMd/0eU15eHtQ66SwS81AmbxZ0+eWXK+dycnJE7Ot33jnnnCNi+U5xX+TVHeX3AdSNjuT6/f3vf1fK3XDDDSL+4osvROyra15nfjfUI0aMwIgRIzyeMwwDc+fOxV/+8hcxdeT5559HSkoKVqxYgWuvvTaw2hKBOUh6YB5SqNg6Rr1nzx5UV1cjKytLPOd0OjFo0CCUlJR4fE1DQwPcbrfyIGqt1uQgwDwkezEPyU62NtTV1dUAgJSUFOX5lJQUcc4sPz8fTqdTPLp3725nlSjKtCYHAeYh2Yt5SHYK+/SsvLw8TJ8+XRy73e6wJac8llFfX6+ck8c25JV4rI5Jp6WlKcf33HOPiO+8806vrztw4ICI5ZtV5E3YAWDnzp2W6kGe6ZSHdujcubOI5Sld3saaATVHu3TpopyTV0tbtWqViOWVnShwOuWhr3HodevWWbpGTU2NiOX7asz30QwYMEDEMTE/f3988cUXlXJPPPGEx2t8+eWXXuvQqVMnEWdnZyvn5J2/5NUo5VX/AGDt2rVerx8Ktn6jPrato/zDOXbsbctHh8OBhIQE5UHUWq3JQYB5SPZiHpKdbG2oe/XqhdTUVBQXF4vn3G433nvvPWRmZtr5VkQeMQdJB8xDspPfXd8HDhzA7t27xfGePXuwY8cOJCUlweVyYerUqXjkkUfQu3dvMSUhLS3tuJVj2pqkpCQRy13QI0eOVMrt2bNHxFOmTBHxLbfcopTr1q2bx/dZunSpcix39ZSVlVmvcASL1hz0hzxdRe7e80Xu3jYMw2u5V199VcRtdbqLHSIxDzt27Cji22+/XcTyanm+nHbaacrxRRddJOI5c+aI2Dxkcv3114u4qKjIWmV9kLu7//3vf4t46NChll6vW9e33w319u3blQ//2HjKTTfdhCVLluCee+7BwYMHMWHCBNTW1uL888/Hm2++2SbmDVLbwBwkHTAPKVT8bqiHDh3q86/tdu3a4aGHHlK2zCOyE3OQdMA8pFAJ+13fujKvoiOvRta1a1cRy3eAA+omHYmJiSI2/4f+9NNPRVxaWipiuYsdYHc3WWNeSe/8888Xsdyl7Yt8t628Eh9FD/nn/sMPP4j4pJNO8vqaM844Q8Tr169XziUnJ4tYnqly//33B1RPM/NKev/85z9FfPLJJ1u6hrwh0j/+8Q97KmYTbspBRESkMTbUREREGmNDTUREpDGOUXth3ii9d+/eIr755ptF7GvsRt6w3LzL1saNG0W8Zs0aEe/atcvfqvpFnn4hj0c1NDQE9X0puOLi4pTjU045RcS+bniSyfnga1xbzl2KLPLvgVmzZon4ySefVMpNnTpVxPfee6+I5WlRgDo10Hw/T6AWLlwo4gkTJijnrN6XId97NHv2bBHr9vuQ36iJiIg0xoaaiIhIY+z69sK8EbnV1Z1kf/zjH0W8evVq5Zy8UIJMntIFQFkX2NeuO1ZVVFSIWO4eys3NVcrJq/mQ/uRhFkDtxpNzrby8XCn35ptvivjqq68WsXklPdltt90mYrnrkCKLvELYXXfdpZwzd4UfY96fO9DubqfTqRzLq+LJq4xZ7er+17/+pRzL07B06+6W8Rs1ERGRxthQExERaSzqu7579uwpYnmf3X79+inl5K6Vw4cPi1i+i9rs22+/FbH5rlzzXYrHmBd/t6O72xt5YxDzv5dd322b3PUtx2Zy/std32bynePyMMlTTz2llDN3wVPbdeDAAREvW7ZMOSfvHy0zz5aRf2/KwyxWyZsSAcCwYcMsva6yslLE8r7a5s1F5JUkdcZv1ERERBpjQ01ERKQxNtREREQai7ox6vHjxyvH8qo68qbn5t2DHn74YRF/9913Ip4/f76l933ssceU42uvvVbE+/btE/Edd9xh6XpEdjjzzDNFbF5VSibvLNSjRw8Rt2/fPjgVo7CT980eO3ascu6TTz4R8aJFi0Qs/z4FgJUrV4r42WefFfGdd97p9X0zMjJEfM0113gt9/rrr4u4uLhYOffKK6+I+Ouvv/Z6jbaC36iJiIg0xoaaiIhIY1HR9T1x4kQRz507VzknT5uSu/euu+46pdzWrVtF7Ks7xptLL71UOW5ubhaxvKH6oUOH/L62L+bpYyec4PlHvmLFClvfN5rIq9aZp6fIK4HJ+bV9+3al3ObNmy2918GDB0Xsa0MYq8477zwRy1NpzNMC5WlcMl8rQqWlpYnYPB1RXoHvmWeeEfFnn33ms74UOp07dxaxefqmvDpdQUGBiOXubUBd4fHuu+8WsbxpDADceuutIpZXHzPnuJz/06ZNE/Hu3bu9/CsiA79RExERaYwNNRERkcYitutbXj1p3rx5Io6JUf82qampEfHw4cNF/OWXXyrl5G4gbxtqmPXp00fE8t21ALB3716P9bPbhRdeqBybu5yOGTVqlHL86KOPBqtKEUf+jPv27aucMx97I3ch+9o/+tNPP/V4bXMXtNU9qL29Jjk52eu5d955R8R1dXVKufj4eBG/9dZbIpb/L5ivN3r0aBGfffbZSrn6+npLdSf7yXf3f/HFF8o5ubtbZp4tc99994lYzpWZM2cq5bp37y5ieRbMqaeeqpSTVyqL9O5uGb9RExERacyvhjo/Px8DBw5EfHw8kpOTMWrUKGXbRAA4cuQIcnNz0aVLF3Tq1Ak5OTnKt1aiQDEPKdyYgxRKfjXUmzZtQm5uLrZu3Yr169ejqakJl1xyyXF34q1atQrLly/Hpk2bUFVVpXRtEQWKeUjhxhykUPJrjNq8+8mSJUuQnJyM0tJSXHjhhairq8PixYuxbNkysctJQUEB+vbti61bt2Lw4MH21fwXPP300yL2NV534oknivjxxx/3Wu7cc88Vscvl8lru888/F7F5fCUc5GkwkaIt5aHdrI55203eFeuBBx4QsTzNEABefvllEZ911lmWri3/P5FXAASAqVOn+lPNkImGHJR3zzL/HunatauI9+/fb+l68pQ/edUzAOjdu7eIzfczyKqqqiy9V6QJaIz62M0BSUlJAIDS0lI0NTUhKytLlOnTpw9cLhdKSko8XqOhoQFut1t5EPmDeUjhZkcOAsxD8qzVDXVLSwumTp2KIUOGoH///gCO/sUUFxd33F9fKSkpXvdVzs/Ph9PpFA/57j+iX8I8pHCzKwcB5iF51urpWbm5uSgrK8OWLVsCqkBeXh6mT58ujt1ud0iTU55OYp6iZIV5+siIESNE3JoVzOwgr7YmrwYUiXTIww8++EDEe/bsUc716tUroHoFmzxd0dsULEDt7t64caOIzf9nLrvssoDqIw8xtRV25SAQ/t+HMnm4Q+7qBtRhDatd377IK0b62hzGPOQQLVrVUE+ePBmrV6/G5s2b0a1bN/F8amoqGhsbUVtbq/wlWVNTg9TUVI/XcjgccDgcrakGRTnmIYWbnTkIMA/JM7+6vg3DwOTJk1FUVIQNGzYc920hPT0dsbGxypZjFRUV2Lt3LzIzM+2pMUU95iGFG3OQQqmd4ccSRnfccQeWLVuGlStXKl0fTqdTbP4wadIkrFmzBkuWLEFCQgKmTJkCAHj33XctvYfb7YbT6fTn3+DRmDFjRPz888+L2Hy3oVVy985LL70kYrmbCgCamppELG94sGbNGqWc/G986qmnRCwvYg+gVfMu5b/gf/zxR6/l5JWCzL9ofL3ODnV1dUhISGjVa3XOQ/Nr5G9H8qpb5k1a5NkHkyZN8vt9fa1MJu/NK28MAgAzZszweL277rpLOZ4zZ47HcvIqUsDRMVhPzJs1rF27VsSvvfaax9cAUL6l2n3Hr+45CNj3+7A15C7osrIy5dx7770nYl9DfHJeLl68WMQDBw5Uysl3/vuaqSKvAmjOvdb45ptvRHzkyJGAr9caVvLQr67vhQsXAgCGDh2qPF9QUICbb74ZwNH/0DExMcjJyUFDQwOys7OV3XGIAsU8pHBjDlIo+dVQW/ny3aFDByxYsAALFixodaWIfGEeUrgxBymUuNY3ERGRxvwaow6FYIzJDBo0SMTHVgk6Rh6jkMuZx5Q//vhjEVdWVvpdh3HjxinH8u4z8hSZr7/+Win33HPPidjX/EvZb37zGxGPHz/eUp1eeOEFS9e2SyDjg6EQzrHBYBo7dqxyvHTpUhHLvwrkHALU/JeZx429jVGbp9ysXr1axObuY9mvfvUrEZeXl3st1xq65yCgTx7+4Q9/UI7l+x7ke2zWrVunlJPvt5Cn7pnHteXdDs2/o4Np165dIpano91www1KOXm3Q7tZyUN+oyYiItIYG2oiIiKNRUXXt45+/etfi/jKK68U8Z///GelXPv27W1938LCQhFfd911tl7bH7p3O0ZqHnbu3Fk5lrv7WtP1/eWXXyrHPXr08FhOXnkKOLpQyDEnnPDzPa07d+5Uyg0YMMDj9eygew4C+uShPDwHqEMo8gZI5iEOeShPnvInb94CAGeccYaIP/roIxEfm+oWarNmzVKOZ86cGbT3Ytc3ERFRG8eGmoiISGOt3pSDArNjxw6Psfnua7lb0Cr5jnXzimPyftkUfcwrzr311lsiHj58uMcY8N71/dhjjynHcjeobNq0acqxtxE3X6uUUfi0tLQox/JsATlurd27d4tYHo6RV6YzkzeHMW/WkZ2dLWJ5NTOrQ4nySmk64DdqIiIijbGhJiIi0hgbaiIiIo1xjFoz8liNP+RpN7GxsV7LydvuEX3wwQcizsrKEvH111+vlDNPmzrmoosuUo7Nu3j90vMA8Oqrr4r4b3/7m9dyFB3+7//+T8R33323ck7Oo/fff1/ETzzxhFJu9uzZIpZXYLzzzjuVcueee67HOvTv39+PGgcfv1ETERFpjA01ERGRxtj1HSHOPvtsEfua0rBnz55QVIfaiA0bNoh4xowZIjZ3Cb7xxhsilrsfzdOsrC50WFZWJuLp06dbqyxFhXvvvVfE5513nnJuyJAhIpbz1byZkTxlrGfPniLu3bu31/c9cuSIx2vrgN+oiYiINMaGmoiISGPs+o5wH374oXL83XffhakmpKOSkhIRr1+/XsQXX3xxwNc+dOiQiM0rR8nd3a3Z352iQ15ennIsD8GcdNJJIp43b55STj72NVQjk/fV3rRpk/+VDSJ+oyYiItIYG2oiIiKNsaEmIiLSGMeoI4S8+o7MPCZ9+PDhUFSH2oj6+noRT5gwQcTmXbHGjBnj8fXm3bheeeUVEcs7acnTsYis2rJli3IsjyObx6+tMI9R/+lPfxKxt53fdODXN+qFCxdiwIABSEhIQEJCAjIzM5XB/SNHjiA3NxddunRBp06dkJOTg5qaGtsrTdGNeUg6YB5SqPjVUHfr1g2PPvooSktLsX37dgwbNgxXXHGFWAd42rRpWLVqFZYvX45NmzahqqoKo0ePDkrFKXoxD0kHzEMKlXaG1aWEvEhKSsJjjz2GMWPG4OSTT8ayZctEN9muXbvQt29flJSUYPDgwZau53a74XQ6A6lSVJJX4pG7wdetW6eUkzdUD6e6ujokJCTYdj3mIfnL7hwEmIehJK8eNmzYMOVcv379RHzgwAERT5o0SSm3efPmINXOOit52OqbyZqbm1FYWIiDBw8iMzMTpaWlaGpqUnbg6dOnD1wulzJX06yhoQFut1t5EFnFPCQdMA8pmPxuqD/55BN06tQJDocDEydORFFREfr164fq6mrExcUhMTFRKZ+SkoLq6mqv18vPz4fT6RSP7t27+/2PoOjDPCQdMA8pFPy+6/uss87Cjh07UFdXh1deeQU33XRTQKu45OXlKasUud1uJqeNfvjhh3BXISiYh6QD5mH4yDMTzLMUIo3fDXVcXBzOOOMMAEB6ejref/99zJs3D9dccw0aGxtRW1ur/BVZU1OD1NRUr9dzOBxwOBz+15yiGvOQdMA8pFAIeMGTlpYWNDQ0ID09HbGxsSguLhbnKioqsHfvXmRmZgb6NkQ+MQ9JB8xDCga/vlHn5eVhxIgRcLlcqK+vx7Jly7Bx40asXbsWTqcTt956K6ZPn46kpCQkJCRgypQpyMzMtHyHI5EVzEPSAfOQQsWvhvrbb7/FuHHjsG/fPjidTgwYMABr164VO+3MmTMHMTExyMnJQUNDA7Kzs/HMM88EpeKkevbZZ0XcrVs3Eefm5oajOkHFPCQdMA8pVAKeR203zhtsnfPOO0/EDz/8sIivuuoqpZwuN5cFYw6rnZiHkU/3HASYh9EgqPOoiYiIKPi4KUeEePfdd0U8fPjwMNaEiIjsxG/UREREGmNDTUREpDE21ERERBpjQ01ERKQxNtREREQaY0NNRESkMTbUREREGmNDTUREpDHtGmrNVjSlINH956x7/ShwbeFn3BbqSIGx8jPWrqGur68PdxUoBHT/OetePwpcW/gZt4U6UmCs/Iy125SjpaUFVVVVMAwDLpcLlZWV2i+cH0xutxvdu3ePmM/BMAzU19cjLS0NMTHa/Z0oMA9VkZSHbSUHgaN5WFFRgX79+kXEZx+oaM1D7db6jomJQbdu3eB2uwEACQkJbf4HYodI+hzawm5AzEPPIuVzaAs5CBzNw1NPPRVA5Hz2doiUz8JqHur95yQREVGUY0NNRESkMW0baofDgQceeAAOhyPcVQkrfg7hxc//KH4O4cPP/mfR+llodzMZERER/Uzbb9RERETEhpqIiEhrbKiJiIg0xoaaiIhIY2yoiYiINKZtQ71gwQL07NkTHTp0wKBBg7Bt27ZwVymo8vPzMXDgQMTHxyM5ORmjRo1CRUWFUubIkSPIzc1Fly5d0KlTJ+Tk5KCmpiZMNY58zEHmoA6Yh8xDGBoqLCw04uLijOeee87YuXOnMX78eCMxMdGoqakJd9WCJjs72ygoKDDKysqMHTt2GCNHjjRcLpdx4MABUWbixIlG9+7djeLiYmP79u3G4MGDjfPOOy+MtY5czEHmoA6Yh8xDwzAMLRvqjIwMIzc3Vxw3NzcbaWlpRn5+fhhrFVrffvutAcDYtGmTYRiGUVtba8TGxhrLly8XZT799FMDgFFSUhKuakYs5iBzUAfMQ+ahYRiGdl3fjY2NKC0tRVZWlnguJiYGWVlZKCkpCWPNQquurg4AkJSUBAAoLS1FU1OT8rn06dMHLpcrqj6XUGAOHsUcDC/m4VHMQw3HqPfv34/m5makpKQoz6ekpKC6ujpMtQqtlpYWTJ06FUOGDEH//v0BANXV1YiLi0NiYqJSNpo+l1BhDjIHdcA8ZB4eo902lwTk5uairKwMW7ZsCXdVKEoxB0kHzMOjtPtG3bVrV7Rv3/64O/hqamqQmpoaplqFzuTJk7F69Wq8/fbb6Natm3g+NTUVjY2NqK2tVcpHy+cSSsxB5qAOmIfMw2O0a6jj4uKQnp6O4uJi8VxLSwuKi4uRmZkZxpoFl2EYmDx5MoqKirBhwwb06tVLOZ+eno7Y2Fjlc6moqMDevXsj+nMJB+Ygc1AHzEPmoRDmm9k8KiwsNBwOh7FkyRKjvLzcmDBhgpGYmGhUV1eHu2pBM2nSJMPpdBobN2409u3bJx6HDh0SZSZOnGi4XC5jw4YNxvbt243MzEwjMzMzjLWOXMxB5qAOmIfMQ8PQdHqWYRjG/PnzDZfLZcTFxRkZGRnG1q1bw12loALg8VFQUCDKHD582LjjjjuMzp07GyeeeKJx5ZVXGvv27QtfpSMcc5A5qAPmIfOQ+1ETERFpTLsxaiIiIvoZG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNBa2hXrBgAXr27IkOHTpg0KBB2LZtW7Deisgj5iDpgHlIgWpnGIZh90VfeukljBs3DosWLcKgQYMwd+5cLF++HBUVFUhOTvb52paWFlRVVSE+Ph7t2rWzu2oUZoZhoL6+HmlpaYiJCV6HTiA5CDAPI1mochBgHpJ3fuWhEQQZGRlGbm6uOG5ubjbS0tKM/Pz8X3xtZWWlAYCPCH9UVlYGI/WEQHLQMJiH0fAIdg4aBvOQD3vy0PY/JxsbG1FaWoqsrCzxXExMDLKyslBSUnJc+YaGBrjdbvEw7P+CTxqKj48P2rX9zUGAeRiNgpmDAPOQrLGSh7Y31Pv370dzczNSUlKU51NSUlBdXX1c+fz8fDidTvFwuVx2V4k0FMxuPH9zEGAeRqNgdyUzD8kKK3kY9ru+8/LyUFdXJx6VlZXhrhJFIeYh6YB5SJ6cYPcFu3btivbt26OmpkZ5vqamBqmpqceVdzgccDgcdleDopi/OQgwD8l+zEOyi+3fqOPi4pCeno7i4mLxXEtLC4qLi5GZmWn32xEdhzlIOmAekm1ady+jb4WFhYbD4TCWLFlilJeXGxMmTDASExON6urqX3xtXV1d2O/C4yP4j7q6umCkni05yDyMjkewc9AwmId82JOHQWmoDcMw5s+fb7hcLiMuLs7IyMgwtm7daul1TMzoeITil2Rrc9AwmIfR8AhFDhoG85CPwPMwKAueBMLtdsPpdIa7GhRkdXV1SEhICHc1vGIeRj7dcxBgHkYDK3kY9ru+iYiIyDs21ERERBpjQ01ERKQxNtREREQaY0NNRESkMTbUREREGmNDTUREpDHb1/qmn8XFxYnYvGTgmjVrRLx161YRX3bZZUq5I0eOBKl2RESt8/HHH4u4f//+In777beVcsOHDw9ZnSIZv1ETERFpjA01ERGRxtj1HUTXXXediAsKCryWGzp0qIjHjBmjnHvxxRdtrxe1XT169BDxTz/9JOJvvvkm4GtfdNFFIl69erVybvr06SJ+9tlnA34valvmzJmjHPfr10/E8irU//nPf0JWp2jCb9REREQaY0NNRESkMXZ920zuPnziiScsveaLL74QMbu6SZaenq4cv/nmmyI+fPiwiF0uV8DvNWPGDBF37NhROScPybDrOzrMnTtXxLm5ucq5du3aifitt94S8cMPP2zp2uPHj1eOH3/8cUuve/nll71eI5LxGzUREZHG2FATERFpjA01ERGRxjhGbbNp06aJOCkpydJrHnzwwWBVh9qILl26iPiGG24Q8QMPPKCU69y5s4jl6VlOp1MpV1dXZ+l9e/bsKeI+ffpYeg1FLjkH5DyMiVG/03311Vci/ve//y3i5uZmr9e+/fbbRTxv3jzlXGxsrMfXmFc6e+WVV7xeP5LxGzUREZHG2FATERFpjF3fATr99NOV49/97neWXldRUSHil156ydY6UdsjT4WRuxx9kafInHTSSco5q13fs2fPFrHcDd7Y2KiUW7RokaXrUdu2YsUKEctDd3v27FHK/f73vxfxrl27vF5v4sSJIn7yySdFbO7qlsvJq+KZ8/jQoUNe3yuS8Rs1ERGRxvxuqDdv3ozLL78caWlpaNeunfIXGHB03de//vWvOOWUU9CxY0dkZWXh888/t6u+RMxB0gLzkELF767vgwcP4pxzzsEtt9yC0aNHH3d+9uzZeOqpp7B06VL06tULM2fORHZ2NsrLy9GhQwdbKq0Tc1fM999/L+L4+Hivr5s1a5aI5bt36Ze11Rw84YSf/7sVFRUp50aOHOnxNfKGBwDwwQcfiFje9KWqqspSHU488UTlODs722O59evXK8evvvqqpetHk7aah7IzzzxTOT755JM9llu8eLFy7Ku7W3bVVVeJ2OFwiLi2tlYp99FHH4l43759lq4dTfxuqEeMGIERI0Z4PGcYBubOnYu//OUvuOKKKwAAzz//PFJSUrBixQpce+21gdWWCMxB0gPzkELF1jHqPXv2oLq6GllZWeI5p9OJQYMGoaSkxONrGhoa4Ha7lQdRa7UmBwHmIdmLeUh2srWhrq6uBgCkpKQoz6ekpIhzZvn5+XA6neLRvXt3O6tEUaY1OQgwD8lezEOyU9inZ+Xl5Smb0rvd7jaVnObxZfO0lmNaWlqUY/MYIIVXKPJQXsHp0ksv9VpOnnb1ySefKOcGDhwYUB2OdcMe4+0+Cnks3Bd5ShcAXH311SKWx9DPOeccr9f461//KuKnn35aOWcey4x0of59OGXKFOU4MTFRxHK+Wt0J8LbbblOOMzIyPJa7++67leNt27ZZun60svUbdWpqKgCgpqZGeb6mpkacM3M4HEhISFAeRK3VmhwEmIdkL+Yh2cnWhrpXr15ITU1FcXGxeM7tduO9995DZmamnW9F5BFzkHTAPCQ7+d31feDAAezevVsc79mzBzt27EBSUhJcLhemTp2KRx55BL179xZTEtLS0jBq1Cg76x1W7du3F/Ef//hH5Zw83aGhoUHEzz77rFLO/Je2v8aOHascz5w5U8S9e/cWsbkr0dzV1Ra1pRyMi4sT8dChQy29Zu/evSK2ukqZL127dhXxfffdZ+k1TU1NXs/Jq/GtWrVKOXfWWWd5fI15mplM3pRm6tSpyrlLLrlExFa740OlLeWhTP75jRs3zmu5+vp6EZuH9C666CIRp6eni9i8iYw8HfCbb74R8TvvvONHjcnvhnr79u3KD+nYeMpNN92EJUuW4J577sHBgwcxYcIE1NbW4vzzz8ebb76pzbxBavuYg6QD5iGFit8N9dChQ33+ddyuXTs89NBDeOihhwKqGJE3zEHSAfOQQiXsd323RfLqPY8++qjXcuvWrROxuUvPqtNOO03EM2bMEPH48eOVcvKdwvId5pMmTVLKyfvK5ubmtqpOZJ1857PVb1LyXb6lpaXKuddee03EhYWFIl65cqXX6yUnJ4v4V7/6lddy8qp6CxcuVM7Jd3fLdwN76+puLXm/bUBdzY3scfnll4u4U6dOXsulpaWJ+I033lDOnX/++SI2r3bnzamnnipieeMNQP09JY/rm3lbOe27776zVAerXnjhBeVY3qc70JkXrcFNOYiIiDTGhpqIiEhjbKiJiIg0xgGgVujWrZvXc/JY8ddffx3we910000injBhgojNuxnJ7yWPQclj3ABw++23e3wfjlcHh3lFOn/FxsYqx9dcc43H2NduRvIUMV8WLVokYnm8Gji6YtYx8nidmbyb3P333y/iDz/80Otr5HnFZ5xxhnLu008/9VFjCib5jna7yVPEAHUa6bx580Rs/j23Zs0aEf/nP/8RsbyaW2tdeeWVIvY1hU7Of6u7iAWK36iJiIg0xoaaiIhIY+0MXxMBw8DtdsPpdIa7GseRpzUVFRWJWO5mBtRNFC644AIRW92uzryyz5///GcRy9Ni5G5FAPjss89ELHcfmqdVyF3hcresebrXkiVLLNW3terq6rRexzgYeSgPY5i71uSpK/L7yqvMBZs8hdA83eX5558Xsfx/Qe7qBtTNFsyr8elG9xwEgpOH8s/Z6mYb5lXhDh8+LGJ5wxXzdK+ysjIRNzc3e3yNWVVVlYjl1dEAdTqgPMz429/+1md9rSgvL/f4PgBQWVnp8b3279/v9/uYWclDfqMmIiLSGBtqIiIijfGub4vklXPM3d2yOXPmiNhXd7fcPS3f2Wi+o3bz5s0ivv7660Xsbd9rAMpGAYsXL1bOzZo1S8RyFybXHw6+pUuXeozNfHV9Z2Vlifjee+/1+JrWmjt3rog//vhj5ZycK/KGHdOmTVPK/e///m/A9aDgkofuzHfVDx8+XMTyCmFbtmxRyh08eFDE8l7S8gYdgNrNLndHm4d+5C54eUU0M3mkVu52bm0XtDy0KHd3m0eE5d/DdnR3+4vfqImIiDTGhpqIiEhjbKiJiIg0xjFqi7Kzsz0+/8MPPyjH77//vsdy5hWXXn/9dY/nzKuZydNdfI1LeyNPqwHUaVjyjkgDBgzw+9oUHHV1dSLevn27ck4+fvzxx0UsT1UBgJKSEhGfe+65ftfBVz7IY9Qck257/vvf/3qMAWDt2rV+X6+mpsZSOTmvzfdoXHbZZSLOyckRsTmvZRMnThTx3r17LdXhpJNOUo7l+358vZc8rh8O/EZNRESkMTbUREREGmPXtxfmjQzkBerlW/fl6QcAsHPnTo/XMy8ub+4KP+bmm29Wjnfs2PELNfVNXuUHAN59910Ry13fY8aMUcrdcccdAb0vBd9PP/3k9ZzVBQflFejGjh0rYnk6FqDmYWFhobUKUlRYsGCBiEeOHGnpNfIGGIDa3S0z5/GNN94o4tZ0R5vf19uULHmVsta+l534jZqIiEhjbKiJiIg0xq5vL+666y7lWL5bUL7L8cUXX/R6DblrWd50wWzdunUilu/WJQo2eaU6edMQM3llpsceeyyodaLIkZiYKOIePXqI+JFHHlHKyXdc+xq2CXQFPvMsGPm95DqsWLEioPexG79RExERacyvhjo/Px8DBw5EfHw8kpOTMWrUKFRUVChljhw5gtzcXHTp0gWdOnVCTk6O5Xl2RFYwDyncmIMUSn411Js2bUJubi62bt2K9evXo6mpCZdccomyQPu0adOwatUqLF++HJs2bUJVVRVGjx5te8UpejEPKdyYgxRKfo1Rv/nmm8rxkiVLkJycjNLSUlx44YWoq6vD4sWLsWzZMgwbNgwAUFBQgL59+2Lr1q0YPHiwfTUPMnm3LDOrfxVPmTJFxJ07d1bOrVmzRsR/+tOfRHzkyBGrVYxa0ZSHVl1yySXKsXnXLW/k3JN98cUXyrG8KxwxB2VlZWUiNufNM888I+KVK1eKWJ4WBahjxd7GjVtL3iHLPP7tbTeuf/7znwG/r50CGqM+tiRcUlISAKC0tBRNTU3KVnx9+vSBy+XyepNUQ0MD3G638iDyB/OQws2OHASYh+RZqxvqlpYWTJ06FUOGDEH//v0BANXV1YiLi1Pu9AOAlJQUVFdXe7xOfn4+nE6neHTv3r21VaIoxDykcLMrBwHmIXnW6ulZubm5KCsrO25DcX/l5eVh+vTp4tjtdmufnOYF5b0ZN26c13M//vijiL/88suA6xStojkPZVdffbVynJCQ4LHc7t27leOrrrrKYzlzjsubHhxrjAB10xgASEtL++XKAiguLhbxsmXLRFxZWWnp9TqxKweBtpmH8kZCCxcuVM7l5+eLeMKECSI2d0F76+I2Py/3UNx5550iNnele5vu5asrXT7Xt29f5dyJJ54o4l27dnm9RrC0qqGePHkyVq9ejc2bN6Nbt27i+dTUVDQ2NqK2tlb5S7Kmpgapqaker+VwOOBwOFpTDYpyzEMKNztzEGAekmd+dX0bhoHJkyejqKgIGzZsQK9evZTz6enpiI2NVf5arqiowN69e5GZmWlPjSnqMQ8p3JiDFEp+faPOzc3FsmXLsHLlSsTHx4uxFqfTiY4dO8LpdOLWW2/F9OnTkZSUhISEBEyZMgWZmZkRdZejHcz7wAaL3GUDACeffHJI3jeYmIetFx8frxwnJydbKnfttdeKWL4j1pxfVg0fPlzE/fr1E/Gtt96qlPO18Ug4MQc9M88OkGcjmGcmyLytRmZ+ftSoUSK2upqZ1XNdunQR8euvv66UO3z4sIjlrm/zCmbySn928quhPjb+MHToUOX5goICsevTnDlzEBMTg5ycHDQ0NCA7O1u5RZ8oUMxDCjfmIIWSXw21la3zOnTogAULFihbnxHZiXlI4cYcpFDiWt9EREQa4+5ZXvzjH/9Qjh966CERy6s5mccyzj77bBGbx/lkixcvDrSKlrhcLuX44osv9ljum2++CUV1yEaxsbEi9jbNysy8HrW3MeoZM2a0vmJ+uvHGG0X84YcfKufmzp0bsnqQ/eTVvnyNKQc6ncrqudZer1OnTiI+99xzRfz3v//d62vsxG/UREREGmNDTUREpDF2fXtRW1urHL/33nsiHjRokIjNcyLlzTfkrslwuf766y2Ve/bZZ4NcE7Kb3FXna5glmMMa5lX15FXGZDEx6neC+++/32M58/Ss5cuXi5jDM23P2LFjRSx3GZtXEvPmtddeU46/++47EV944YWWrufrxr/y8nIRW11ZrqioSMTr1q2z9JpA8Rs1ERGRxthQExERaYxd3148/fTTPo+9mTp1qqVy8kpPjz76qOV6WdGhQwcR//a3v/VaTt4YZP369bbWgYKvqalJxNOmTVPOyXvwytsqervL2x8vvPCCiB9++GHlnHk/4mPM61d76/r+/PPPlWNfO01R2yLPiLFDjx49RLxt2zblnLcVGM1d1SNGjLC1TsHCb9REREQaY0NNRESkMTbUREREGuMYtc3q6upE3NLSImLz9BR5xyA7yGOA8rhhdna219fIY43exhZJX/K0k3nz5innzMfH3HvvvcrxBRdcYOm97r77bhHPnz9fxL52t+rYsaOIrU7/27Fjh3Lc3Nxs6XUUfW677TYRyztfAer/DTmWp4u1JfxGTUREpDE21ERERBprZ1jZry2E3G43nE5nuKthC3kVnaSkJOWc3NU8cuRIEe/evdvStc3TXYYNGybi1atXe32dvEj+kCFD/H5fu9TV1SEhISGk7+mPSMpDmXnzjsLCQkuvk7uxGxsbRSyvxAcAAwYMEPG4ceNEfGyPZk+qqqpEnJGRoZzbt2+fpfq1hu45CERuHraWPO1q06ZNIjavTCav2if/Hk5JSQli7VrHSh7yGzUREZHG2FATERFpjHd9B9HLL78s4gkTJijnTj/9dBG/8cYbIh41apRSrqamRsSnnXaaiO+77z6l3BVXXOGxDvX19cpxQUGBiEPd3U3h99lnnynHcn742tjj1Vdf9fh8165dlWNz17UV8t7swezqprYvLy9PxHJ3t3kEVx7iayurj/nCb9REREQaY0NNRESkMTbUREREGuP0rBD58ssvlWN55xe7HTp0SMTmlXhWrFgRtPf1h+5TYyI1D82uueYaES9btixo7yOv2AcA06dPF/G//vUvEcs7ggWb7jkIRE8eWrV9+3YRp6eni1heBRIAKioqRCzvICj/btSF7dOzFi5ciAEDBiAhIQEJCQnIzMxUboQ6cuQIcnNz0aVLF3Tq1Ak5OTnKzVBEdmAekg6YhxQqfjXU3bp1w6OPPorS0lJs374dw4YNwxVXXIGdO3cCOLon7qpVq7B8+XJs2rQJVVVVGD16dFAqTtGLeUg6YB5SqATc9Z2UlITHHnsMY8aMwcknn4xly5ZhzJgxAIBdu3ahb9++KCkpweDBgy1dL1K7evr3768cy9MMrr32Wr+vZ/6xffXVVyK+9NJLRazrFCy7ux2Zh62TmJgo4smTJ4v4wQcfbNX15FXG5I1BNmzYoJT74IMPWnV9OwWj65t5aC95JTIA2LZtm4hdLpeIzb8Pv//+exEPHDhQxHv37rW7igEL6spkzc3NKCwsxMGDB5GZmYnS0lI0NTUhKytLlOnTpw9cLhdKSkq8XqehoQFut1t5EFnFPCQdMA8pmPxuqD/55BN06tQJDocDEydORFFREfr164fq6mrExcUpf6EDR9dWra6u9nq9/Px8OJ1O8ejevbvf/wiKPsxD0gHzkELB75XJzjrrLOzYsQN1dXV45ZVXcNNNNymLo/srLy9PuQPU7XZHZHKWlZUpx/n5+SIuLy/3+rqJEyeK+PXXXxex+a/ypUuXBlrFNoV5aI/a2loRP/LIIx5j8o55GFzyhhqA2qXds2dPEZvv+n7qqadErGN3t7/8bqjj4uJwxhlnADh6e/z777+PefPm4ZprrkFjYyNqa2uVvyJramqQmprq9XoOh+O4naCIfgnzkHTAPKRQCHjBk5aWFjQ0NCA9PR2xsbEoLi4W5yoqKrB3715kZmYG+jZEPjEPSQfMQwoGv75R5+XlYcSIEXC5XKivr8eyZcuwceNGrF27Fk6nE7feeiumT5+OpKQkJCQkYMqUKcjMzLR8hyORFcxD0gHzkELFr4b622+/xbhx47Bv3z44nU4MGDAAa9euxcUXXwwAmDNnDmJiYpCTk4OGhgZkZ2fjmWeeCUrF2zp5zNo8fi2bNWtWKKrTpjAPSQfMw9CTp2HJ9wIUFRUp5eSpgZGAS4hSWOi+fCPzMPLpnoMA89Ds/fffF/HBgwdF3JYb6qDOoyYiIqLg8/uubyIionCQVxmLJvxGTUREpDE21ERERBpjQ01ERKQxNtREREQaY0NNRESkMTbUREREGmNDTUREpDE21ERERBrTrqHWbEVTChLdf866148C1xZ+xm2hjhQYKz9j7Rrq+vr6cFeBQkD3n7Pu9aPAtYWfcVuoIwXGys9Yu005WlpaUFVVBcMw4HK5UFlZqf3C+cHkdrvRvXv3iPkcDMNAfX090tLSEBOj3d+JAvNQFUl52FZyEDiahxUVFejXr19EfPaBitY81G6t75iYGHTr1g1utxsAkJCQ0OZ/IHaIpM+hLewGxDz0LFI+h7aQg8DRPDz11FMBRM5nb4dI+Sys5qHef04SERFFOTbUREREGtO2oXY4HHjggQfgcDjCXZWw4ucQXvz8j+LnED787H8WrZ+FdjeTERER0c+0/UZNREREbKiJiIi0xoaaiIhIY2yoiYiINMaGmoiISGPaNtQLFixAz5490aFDBwwaNAjbtm0Ld5WCKj8/HwMHDkR8fDySk5MxatQoVFRUKGWOHDmC3NxcdOnSBZ06dUJOTg5qamrCVOPIxxxkDuqAecg8hKGhwsJCIy4uznjuueeMnTt3GuPHjzcSExONmpqacFctaLKzs42CggKjrKzM2LFjhzFy5EjD5XIZBw4cEGUmTpxodO/e3SguLja2b99uDB482DjvvPPCWOvIxRxkDuqAecg8NAzD0LKhzsjIMHJzc8Vxc3OzkZaWZuTn54exVqH17bffGgCMTZs2GYZhGLW1tUZsbKyxfPlyUebTTz81ABglJSXhqmbEYg4yB3XAPGQeGoZhaNf13djYiNLSUmRlZYnnYmJikJWVhZKSkjDWLLTq6uoAAElJSQCA0tJSNDU1KZ9Lnz594HK5oupzCQXm4FHMwfBiHh7FPNRwjHr//v1obm5GSkqK8nxKSgqqq6vDVKvQamlpwdSpUzFkyBD0798fAFBdXY24uDgkJiYqZaPpcwkV5iBzUAfMQ+bhMdptc0lAbm4uysrKsGXLlnBXhaIUc5B0wDw8Srtv1F27dkX79u2Pu4OvpqYGqampYapV6EyePBmrV6/G22+/jW7duonnU1NT0djYiNraWqV8tHwuocQcZA7qgHnIPDxGu4Y6Li4O6enpKC4uFs+1tLSguLgYmZmZYaxZcBmGgcmTJ6OoqAgbNmxAr169lPPp6emIjY1VPpeKigrs3bs3oj+XcGAOMgd1wDxkHgphvpnNo8LCQsPhcBhLliwxysvLjQkTJhiJiYlGdXV1uKsWNJMmTTKcTqexceNGY9++feJx6NAhUWbixImGy+UyNmzYYGzfvt3IzMw0MjMzw1jryMUcZA7qgHnIPDQMTadnGYZhzJ8/33C5XEZcXJyRkZFhbN26NdxVCioAHh8FBQWizOHDh4077rjD6Ny5s3HiiScaV155pbFv377wVTrCMQeZgzpgHjIPuR81ERGRxrQboyYiIqKfsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo2xoSYiItIYG2oiIiKNsaEmIiLSGBtqIiIijbGhJiIi0hgbaiIiIo39P4lCIkqX3bb+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "BATCH_SIZE = 60000\n",
    "TEST_BATCH_SIZE = 1000\n",
    "#put image in the upper left corner is the first image, bottom right corner is the second image\n",
    "\n",
    "new_trainset = []\n",
    "new_testset = []\n",
    "\n",
    "for i in range(60000):\n",
    "    x1 = train_dataset[torch.randint(len(train_dataset), size=(1,)).item()][0]\n",
    "    x2 = train_dataset[torch.randint(len(train_dataset), size=(1,)).item()][0]\n",
    "    new_trainset.append(make_new_sample(x1, x2))\n",
    "\n",
    "for i in range(10000):\n",
    "    x1 = test_dataset[torch.randint(len(test_dataset), size=(1,)).item()][0]\n",
    "    x2 = test_dataset[torch.randint(len(test_dataset), size=(1,)).item()][0]\n",
    "    new_testset.append(make_new_sample(x1, x2))\n",
    "\n",
    "# show random samples from new_trainset\n",
    "fig,ax = plt.subplots(2,3, figsize=(5,4))\n",
    "# trainset\n",
    "ax[0,0].imshow(new_trainset[0][0].squeeze(), cmap='gray')\n",
    "ax[0,1].imshow(new_trainset[1][0].squeeze(), cmap='gray')\n",
    "ax[0,2].imshow(new_trainset[2][0].squeeze(), cmap='gray')\n",
    "# testset\n",
    "ax[1,0].imshow(new_testset[0][0].squeeze(), cmap='gray')\n",
    "ax[1,1].imshow(new_testset[1][0].squeeze(), cmap='gray')\n",
    "ax[1,2].imshow(new_testset[2][0].squeeze(), cmap='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n",
    "\n",
    "# create the new train and test dataloaders\n",
    "\n",
    "new_train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=new_trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "new_test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=new_testset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader shape:  torch.Size([60000, 1, 36, 36])\n",
      "Test dataloader shape:  torch.Size([1000, 1, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new train and test dataloaders\n",
    "print(\"Train dataloader shape: \", next(iter(new_train_dataloader)).shape)\n",
    "print(\"Test dataloader shape: \", next(iter(new_test_dataloader)).shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create the Multi Task Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a CNN with the following architecture:\n",
    "- Encoder :\n",
    "    - 2 convolution layers of 10 and 20 channels\n",
    "    - A liner layer of 50 neurons\n",
    "    - Each convolution layer has kernel size of 5, followed by ReLU activation and max pooling layer\n",
    "- Decoder : each decoder is a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([60000, 1, 36, 36])) that is different to the input size (torch.Size([60000, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (36) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest loss: \u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     67\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m train(model, new_train_dataloader, optimizer, criterion, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     69\u001b[0m \u001b[39m# test the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m test(model, new_test_dataloader, criterion)\n",
      "Cell \u001b[1;32mIn [23], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m# ===================forward=====================\u001b[39;00m\n\u001b[0;32m     48\u001b[0m output \u001b[39m=\u001b[39m model(img)\n\u001b[1;32m---> 49\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, img)\n\u001b[0;32m     50\u001b[0m \u001b[39m# ===================backward====================\u001b[39;00m\n\u001b[0;32m     51\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3291\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\osour\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (36) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# create the new model\n",
    "# encoder has two convolution layers of 10 and 20 channels, a linear layer with 50 output .\n",
    "# each convolutional layer has kernel site of 5 and is followed by relu and maxpool. \n",
    "# each decoder is a linear layer with 20*4*4 input and 20*4*4 output, followed by a convolutional layer of 10 channels, relu and maxpool.\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(10, 20, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(720, 50)            \n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# create the new model\n",
    "model = Autoencoder()\n",
    "# move the model to the GPU\n",
    "model = model.to(device)\n",
    "# create the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# create the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# train the model\n",
    "def train(model, train_loader, optimizer, criterion, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for data in train_loader:\n",
    "            img = data\n",
    "            img = img.to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(img)\n",
    "            loss = criterion(output, img)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, epochs, loss.item()))\n",
    "\n",
    "# test the model\n",
    "def test(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            img = data\n",
    "            img = img.to(device)\n",
    "            output = model(img)\n",
    "            loss = criterion(output, img)\n",
    "        print('Test loss: ', loss.item())\n",
    "\n",
    "# train the model\n",
    "train(model, new_train_dataloader, optimizer, criterion, epochs=10)\n",
    "# test the model\n",
    "test(model, new_test_dataloader, criterion)\n",
    "\n",
    "# show the results\n",
    "# get the first batch of images\n",
    "\n",
    "dataiter = iter(new_test_dataloader)\n",
    "images = dataiter.next()\n",
    "\n",
    "# move images to the GPU\n",
    "images = images.to(device)\n",
    "\n",
    "# get sample outputs\n",
    "\n",
    "output = model(images)  \n",
    "# prep images for display\n",
    "images = images.cpu().numpy()\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(TEST_BATCH_SIZE, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.cpu().detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Train the Multi Task Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9566ee846e0e5475f3731207e71ee4a96d604221359f666805a9fa43f54da3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
